{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10406d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emcee\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import symbolic_pofk.syren_new as syren_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318bafd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: /home/x-ctirapongpra/scratch/tailed-uniform-sbi/mcmc_samples/circle_grid\n"
     ]
    }
   ],
   "source": [
    "# Grid configuration\n",
    "L, N = 1000, 64\n",
    "kf = 2*np.pi/L\n",
    "knyq = np.pi*N/L\n",
    "kedges = np.arange(0, knyq, kf)\n",
    "kcenters = (kedges[:-1] + kedges[1:])/2\n",
    "a = 1.0\n",
    "\n",
    "# Parameter ranges\n",
    "param_1_range = (0.24, 0.40)   # Om\n",
    "param_2_range = (0.61, 0.73)   # h\n",
    "param_ranges = [param_1_range, param_2_range]\n",
    "\n",
    "# Prior parameters\n",
    "param_1_mean = (param_1_range[0] + param_1_range[1]) / 2  # Om mean\n",
    "param_2_mean = (param_2_range[0] + param_2_range[1]) / 2  # h mean\n",
    "param_1_std = 0.1 * (param_1_range[1] - param_1_range[0])   # Om std\n",
    "param_2_std = 0.1 * (param_2_range[1] - param_2_range[0])   # h std\n",
    "\n",
    "# MCMC configuration\n",
    "MCMC_CONFIG = {\n",
    "    'num_samples': 3000,    # samples per walker\n",
    "    'warmup_steps': 500,     # burn-in steps\n",
    "    'num_chains': 4          # number of walkers\n",
    "}\n",
    "\n",
    "# Test point configuration\n",
    "N_RADII = 20\n",
    "N_ANGLES = 30\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"/home/x-ctirapongpra/scratch/tailed-uniform-sbi/mcmc_samples/circle_grid\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f54dc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward model and likelihood functions\n",
    "\n",
    "def forward_model_deterministic(theta):\n",
    "    \"\"\"\n",
    "    Deterministic forward model: theta -> P_theory(k)\n",
    "    Returns noiseless theoretical power spectrum\n",
    "\n",
    "    Args:\n",
    "        theta: [Om, h] cosmological parameters\n",
    "    Returns:\n",
    "        P_theory: theoretical power spectrum (no noise)\n",
    "    \"\"\"\n",
    "    Om, h = theta\n",
    "\n",
    "    # Fixed cosmological parameters\n",
    "    As = 2.105  # 10^9 A_s\n",
    "    Ob = 0.02242 / h ** 2\n",
    "    ns = 0.9665\n",
    "    w0 = -1.0\n",
    "    wa = 0.0\n",
    "    mnu = 0.0\n",
    "\n",
    "    # Get theoretical power spectrum (no noise)\n",
    "    pk_syren_theory = syren_new.pnl_new_emulated(\n",
    "        kcenters, As, Om, Ob, h, ns, mnu, w0, wa, a=a\n",
    "    )\n",
    "\n",
    "    return pk_syren_theory\n",
    "\n",
    "\n",
    "def compute_cosmic_variance_std(P_theory):\n",
    "    \"\"\"\n",
    "    Compute cosmic variance uncertainties for power spectrum\n",
    "\n",
    "    Args:\n",
    "        P_theory: theoretical power spectrum\n",
    "    Returns:\n",
    "        std_mode: standard deviation per k-bin\n",
    "    \"\"\"\n",
    "    var_single = np.abs(P_theory)**2\n",
    "    Nk = L**3 * kcenters**2 * kf / (2*np.pi**2)\n",
    "    var_mode = var_single * 2 / Nk\n",
    "    std_mode = np.sqrt(var_mode)\n",
    "    return std_mode\n",
    "\n",
    "\n",
    "def log_prior(theta):\n",
    "    \"\"\"\n",
    "    Log prior probability (Normal distributions)\n",
    "\n",
    "    Args:\n",
    "        theta: [Om, h] parameters\n",
    "    Returns:\n",
    "        log_prior: log prior probability\n",
    "    \"\"\"\n",
    "    Om, h = theta\n",
    "\n",
    "    # Normal prior for Om\n",
    "    log_prior_Om = -0.5 * ((Om - param_1_mean) / param_1_std)**2\n",
    "\n",
    "    # Normal prior for h\n",
    "    log_prior_h = -0.5 * ((h - param_2_mean) / param_2_std)**2\n",
    "\n",
    "    return log_prior_Om + log_prior_h\n",
    "\n",
    "\n",
    "def log_likelihood(theta, x_obs):\n",
    "    \"\"\"\n",
    "    Log likelihood function\n",
    "\n",
    "    Args:\n",
    "        theta: [Om, h] parameters\n",
    "        x_obs: observed power spectrum data\n",
    "    Returns:\n",
    "        log_likelihood: log likelihood value\n",
    "    \"\"\"\n",
    "    # Forward model\n",
    "    P_theory = forward_model_deterministic(theta)\n",
    "\n",
    "    # Noise model\n",
    "    std_mode = compute_cosmic_variance_std(P_theory)\n",
    "\n",
    "    # Gaussian likelihood\n",
    "    log_like = -0.5 * np.sum(((x_obs - P_theory) / std_mode)\n",
    "                             ** 2) - np.sum(np.log(std_mode))\n",
    "\n",
    "    return log_like\n",
    "\n",
    "\n",
    "def log_probability(theta, x_obs):\n",
    "    \"\"\"\n",
    "    Log posterior probability\n",
    "\n",
    "    Args:\n",
    "        theta: [Om, h] parameters\n",
    "        x_obs: observed power spectrum data\n",
    "    Returns:\n",
    "        log_posterior: log posterior probability\n",
    "    \"\"\"\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "\n",
    "    return lp + log_likelihood(theta, x_obs)\n",
    "\n",
    "\n",
    "def run_mcmc_inference(x_obs, num_samples=1000, warmup_steps=500, num_chains=4,\n",
    "                      verbose=False):\n",
    "    \"\"\"\n",
    "    Run MCMC inference using emcee sampler\n",
    "\n",
    "    Args:\n",
    "        x_obs: observed power spectrum data (numpy array)\n",
    "        num_samples: number of MCMC samples per chain\n",
    "        warmup_steps: number of warmup steps\n",
    "        num_chains: number of parallel walkers\n",
    "        verbose: whether to print progress\n",
    "\n",
    "    Returns:\n",
    "        samples: dictionary of parameter samples\n",
    "        sampler: emcee sampler object for diagnostics\n",
    "    \"\"\"\n",
    "    # Ensure x_obs is numpy array\n",
    "    if not isinstance(x_obs, np.ndarray):\n",
    "        x_obs = np.array(x_obs)\n",
    "\n",
    "    # Initialize walkers with random positions within prior range\n",
    "    pos = np.random.rand(num_chains, 2)\n",
    "    pos[:, 0] = pos[:, 0] * \\\n",
    "        (param_1_range[1] - param_1_range[0]) + param_1_range[0]  # Om\n",
    "    pos[:, 1] = pos[:, 1] * \\\n",
    "        (param_2_range[1] - param_2_range[0]) + param_2_range[0]  # h\n",
    "\n",
    "    # Set up sampler\n",
    "    sampler = emcee.EnsembleSampler(\n",
    "        num_chains, 2, log_probability, args=(x_obs,))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Running MCMC: {num_samples} samples, {warmup_steps} warmup, {num_chains} walkers\")\n",
    "\n",
    "    # Run warmup\n",
    "    state = sampler.run_mcmc(pos, warmup_steps)\n",
    "    sampler.reset()\n",
    "\n",
    "    # Run production\n",
    "    sampler.run_mcmc(state, num_samples)\n",
    "\n",
    "    # Extract samples\n",
    "    chain = sampler.get_chain(flat=True)\n",
    "    samples_np = {\n",
    "        'Om': chain[:, 0],\n",
    "        'h': chain[:, 1]\n",
    "    }\n",
    "\n",
    "    return samples_np, sampler\n",
    "\n",
    "\n",
    "def simulator(theta):\n",
    "    \"\"\"\n",
    "    Simulator with noise: theta -> P(k) with cosmic variance\n",
    "\n",
    "    Args:\n",
    "        theta: [Om, h] cosmological parameters\n",
    "    Returns:\n",
    "        P_noisy: power spectrum with cosmic variance noise\n",
    "    \"\"\"\n",
    "    # Get noiseless prediction\n",
    "    P_theory = forward_model_deterministic(theta)\n",
    "\n",
    "    # Get noise level\n",
    "    std_mode = compute_cosmic_variance_std(P_theory)\n",
    "\n",
    "    # Add noise\n",
    "    P_noisy = P_theory + std_mode * np.random.randn(*P_theory.shape)\n",
    "\n",
    "    return P_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421b0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_points(n_radii=20, n_angles=30):\n",
    "    \"\"\"\n",
    "    Create test points on concentric circles in parameter space.\n",
    "\n",
    "    Args:\n",
    "        n_radii: number of radii to sample\n",
    "        n_angles: number of angles per circle\n",
    "\n",
    "    Returns:\n",
    "        test_points: array of shape (n_points, 2) with [Om, h] values\n",
    "        radii: array of radii corresponding to each test point\n",
    "    \"\"\"\n",
    "    # Calculate prior center and max radius\n",
    "    prior_center = np.array([\n",
    "        (param_1_range[0] + param_1_range[1]) / 2,  # Om center\n",
    "        (param_2_range[0] + param_2_range[1]) / 2   # h center\n",
    "    ])\n",
    "\n",
    "    # Max radius is distance to corner\n",
    "    max_radius = np.sqrt(\n",
    "        ((param_1_range[1] - param_1_range[0]) / 2) ** 2 +\n",
    "        ((param_2_range[1] - param_2_range[0]) / 2) ** 2\n",
    "    )\n",
    "\n",
    "    # Start with center point\n",
    "    test_points = [prior_center.copy()]\n",
    "    radii = [0.0]\n",
    "\n",
    "    # Create concentric circles\n",
    "    for radius in np.linspace(0.2 * max_radius, 0.9 * max_radius, n_radii):\n",
    "        for angle in np.linspace(0, 2*np.pi, n_angles, endpoint=False):\n",
    "            x = prior_center[0] + radius * np.cos(angle)\n",
    "            y = prior_center[1] + radius * np.sin(angle)\n",
    "\n",
    "            # Only keep points within parameter bounds\n",
    "            if (param_ranges[0][0] <= x <= param_ranges[0][1] and\n",
    "                param_ranges[1][0] <= y <= param_ranges[1][1]):\n",
    "                test_points.append([x, y])\n",
    "                radii.append(radius)\n",
    "\n",
    "    return np.array(test_points), np.array(radii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e60a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 475 test points\n",
      "Saved test points to: /home/x-ctirapongpra/scratch/tailed-uniform-sbi/mcmc_samples/circle_grid/test_points.npy\n",
      "Saved radii to: /home/x-ctirapongpra/scratch/tailed-uniform-sbi/mcmc_samples/circle_grid/radii.npy\n"
     ]
    }
   ],
   "source": [
    "# Generate test points\n",
    "test_points, radii = create_test_points(n_radii=N_RADII, n_angles=N_ANGLES)\n",
    "\n",
    "n_test_points = len(test_points)\n",
    "print(f\"Generated {n_test_points} test points\")\n",
    "\n",
    "# Save test points metadata\n",
    "np.save(os.path.join(OUTPUT_DIR, \"test_points.npy\"), test_points)\n",
    "np.save(os.path.join(OUTPUT_DIR, \"radii.npy\"), radii)\n",
    "print(f\"Saved test points to: {OUTPUT_DIR}/test_points.npy\")\n",
    "print(f\"Saved radii to: {OUTPUT_DIR}/radii.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d478e473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example test point (index 19): Om=0.30381966011250106, h=0.6582442949541505\n"
     ]
    }
   ],
   "source": [
    "# extract the 19th test point as an example\n",
    "example_index = 19\n",
    "example_theta = test_points[example_index]\n",
    "print(f\"Example test point (index {example_index}): Om={example_theta[0]}, h={example_theta[1]}\")\n",
    "\n",
    "x_obs = simulator(example_theta)\n",
    "\n",
    "# Run MCMC inference\n",
    "samples, sampler = run_mcmc_inference(\n",
    "    x_obs,\n",
    "    num_samples=MCMC_CONFIG['num_samples'],\n",
    "    warmup_steps=MCMC_CONFIG['warmup_steps'],\n",
    "    num_chains=MCMC_CONFIG['num_chains'],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d62b9366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running MCMC for 475 test points...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCMC Progress:  43%|████▎     | 202/475 [03:09<25:19,  5.57s/it]/home/x-ctirapongpra/.conda/envs/2024.02-py311/tailed-uniform/lib/python3.10/site-packages/symbolic_pofk/linear_new.py:352: RuntimeWarning: invalid value encountered in log\n",
      "  s = 44.5 * np.log(9.83 / om0h2) / np.sqrt(1.0 + 10.0 * ombh2**0.75)\n",
      "/home/x-ctirapongpra/.conda/envs/2024.02-py311/tailed-uniform/lib/python3.10/site-packages/symbolic_pofk/linear_new.py:354: RuntimeWarning: invalid value encountered in log\n",
      "  np.log(431.0 * om0h2) * ombom0 + 0.38 * \\\n",
      "/home/x-ctirapongpra/.conda/envs/2024.02-py311/tailed-uniform/lib/python3.10/site-packages/symbolic_pofk/linear_new.py:355: RuntimeWarning: invalid value encountered in log\n",
      "  np.log(22.3 * om0h2) * ombom0**2\n",
      "/home/x-ctirapongpra/.conda/envs/2024.02-py311/tailed-uniform/lib/python3.10/site-packages/symbolic_pofk/linear_new.py:304: RuntimeWarning: invalid value encountered in scalar power\n",
      "  (Omega ** (4/7) - OL + (1 + Omega/2) * (1 + OL/70))\n",
      "/home/x-ctirapongpra/.conda/envs/2024.02-py311/tailed-uniform/lib/python3.10/site-packages/symbolic_pofk/linear_new.py:319: RuntimeWarning: invalid value encountered in scalar power\n",
      "  yfs = 17.2 * fnu * (1 + 0.488 / fnu ** (7/6)) * (Nnu * q / fnu) ** 2\n",
      "MCMC Progress:  43%|████▎     | 202/475 [03:09<04:16,  1.07it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Probability function returned NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m x_obs \u001b[38;5;241m=\u001b[39m simulator(theta_test)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Run MCMC inference\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m samples, sampler \u001b[38;5;241m=\u001b[39m \u001b[43mrun_mcmc_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMCMC_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_samples\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMCMC_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwarmup_steps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMCMC_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_chains\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Convert to array format\u001b[39;00m\n\u001b[1;32m     23\u001b[0m samples_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack([samples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOm\u001b[39m\u001b[38;5;124m'\u001b[39m], samples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "Cell \u001b[0;32mIn[3], line 142\u001b[0m, in \u001b[0;36mrun_mcmc_inference\u001b[0;34m(x_obs, num_samples, warmup_steps, num_chains, verbose)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning MCMC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwarmup_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m warmup, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_chains\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m walkers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Run warmup\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_mcmc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m sampler\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Run production\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/2024.02-py311/tailed-uniform/lib/python3.10/site-packages/emcee/ensemble.py:450\u001b[0m, in \u001b[0;36mEnsembleSampler.run_mcmc\u001b[0;34m(self, initial_state, nsteps, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m     initial_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_previous_state\n\u001b[1;32m    449\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m results \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(initial_state, iterations\u001b[38;5;241m=\u001b[39mnsteps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# Store so that the ``initial_state=None`` case will work\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/2024.02-py311/tailed-uniform/lib/python3.10/site-packages/emcee/ensemble.py:409\u001b[0m, in \u001b[0;36mEnsembleSampler.sample\u001b[0;34m(self, initial_state, log_prob0, rstate0, blobs0, iterations, tune, skip_initial_state_check, thin_by, thin, store, progress, progress_kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_moves, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weights)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Propose\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m state, accepted \u001b[38;5;241m=\u001b[39m \u001b[43mmove\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m state\u001b[38;5;241m.\u001b[39mrandom_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tune:\n",
      "File \u001b[0;32m~/.conda/envs/2024.02-py311/tailed-uniform/lib/python3.10/site-packages/emcee/moves/red_blue.py:93\u001b[0m, in \u001b[0;36mRedBlueMove.propose\u001b[0;34m(self, model, state)\u001b[0m\n\u001b[1;32m     90\u001b[0m q, factors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_proposal(s, c, model\u001b[38;5;241m.\u001b[39mrandom)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Compute the lnprobs of the proposed position.\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m new_log_probs, new_blobs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_log_prob_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Loop over the walkers and update them accordingly.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (j, f, nlp) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mzip\u001b[39m(all_inds[S1], factors, new_log_probs)\n\u001b[1;32m     98\u001b[0m ):\n",
      "File \u001b[0;32m~/.conda/envs/2024.02-py311/tailed-uniform/lib/python3.10/site-packages/emcee/ensemble.py:551\u001b[0m, in \u001b[0;36mEnsembleSampler.compute_log_prob\u001b[0;34m(self, coords)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# Check for log_prob returning NaN.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(log_prob)):\n\u001b[0;32m--> 551\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbability function returned NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_prob, blob\n",
      "\u001b[0;31mValueError\u001b[0m: Probability function returned NaN"
     ]
    }
   ],
   "source": [
    "# Run MCMC for each test point\n",
    "print(f\"\\nRunning MCMC for {n_test_points} test points...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# start from idx = 19\n",
    "\n",
    "for idx, theta_test in enumerate(tqdm(test_points, desc=\"MCMC Progress\")):\n",
    "    if idx < 168:\n",
    "        continue\n",
    "    # Generate observed data at this test point\n",
    "    x_obs = simulator(theta_test)\n",
    "\n",
    "    # Run MCMC inference\n",
    "    samples, sampler = run_mcmc_inference(\n",
    "        x_obs,\n",
    "        num_samples=MCMC_CONFIG['num_samples'],\n",
    "        warmup_steps=MCMC_CONFIG['warmup_steps'],\n",
    "        num_chains=MCMC_CONFIG['num_chains'],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Convert to array format\n",
    "    samples_array = np.column_stack([samples['Om'], samples['h']])\n",
    "\n",
    "    # Save posterior samples\n",
    "    output_file = os.path.join(OUTPUT_DIR, f\"theta_{idx:04d}.npy\")\n",
    "    np.save(output_file, samples_array)\n",
    "\n",
    "print(f\"Saved {n_test_points} posterior sample files to: {OUTPUT_DIR}/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tailed-uniform",
   "language": "python",
   "name": "tailed-uniform"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
