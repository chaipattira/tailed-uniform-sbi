@article{cranmer2020,
  title={The frontier of simulation-based inference},
  author={Cranmer, Kyle and Brehmer, Johann and Louppe, Gilles},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={48},
  pages={30055--30062},
  year={2020},
  publisher={National Acad Sciences}
}

@inproceedings{lueckmann2021,
  title={Benchmarking simulation-based inference},
  author={Lueckmann, Jan-Matthis and Boelts, Jan and Greenberg, David and Gon{\c{c}}alves, Pedro J and Macke, Jakob H},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={343--351},
  year={2021},
  organization={PMLR}
}

@article{ho2024,
  title={LtU-ILI: An All-in-One Framework for Implicit Inference in Astrophysics and Cosmology},
  author={Ho, Matthew and Farren, Gwendolyn M and Shao, Helen and Anau Montel, Natalí and Modi, Chirag and Régaldo-Saint Blancard, Bruno and Lemos, Pablo and Coogan, Adam and Hezaveh, Yashar and Perreault-Levasseur, Laurence and Wandelt, Benjamin D and de Santi, Natalí SM},
  journal={The Open Journal of Astrophysics},
  volume={7},
  year={2024},
  note={arXiv:2402.05137}
}

@inproceedings{papamakarios2016,
  title={Fast $\epsilon$-free inference of simulation models with {B}ayesian conditional density estimation},
  author={Papamakarios, George and Murray, Iain},
  booktitle={Advances in Neural Information Processing Systems},
  volume={29},
  pages={1028--1036},
  year={2016}
}

@inproceedings{greenberg2019,
  title={Automatic posterior transformation for likelihood-free inference},
  author={Greenberg, David and Nonnenmacher, Marcel and Macke, Jakob},
  booktitle={International Conference on Machine Learning},
  pages={2404--2414},
  year={2019},
  organization={PMLR}
}

@article{papamakarios2017maf,
  title={Masked autoregressive flow for density estimation},
  author={Papamakarios, George and Pavlakou, Theo and Murray, Iain},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{germain2015,
  title={{MADE}: Masked autoencoder for distribution estimation},
  author={Germain, Mathieu and Gregor, Karol and Murray, Iain and Larochelle, Hugo},
  booktitle={International Conference on Machine Learning},
  pages={881--889},
  year={2015},
  organization={PMLR}
}

@article{papamakarios2019,
  title={Sequential neural likelihood: Fast likelihood-free inference with autoregressive flows},
  author={Papamakarios, George and Sterratt, David C and Murray, Iain},
  journal={Proceedings of Machine Learning Research},
  volume={89},
  pages={837--848},
  year={2019}
}

@inproceedings{lopez-paz2016,
  title={Revisiting classifier two-sample tests},
  author={Lopez-Paz, David and Oquab, Maxime},
  booktitle={International Conference on Learning Representations},
  year={2017},
  note={arXiv:1610.06545}
}

@article{lueckmann2017,
  title={Flexible statistical inference for mechanistic models of neural dynamics},
  author={Lueckmann, Jan-Matthis and Gonçalves, Pedro J and Bassetto, Giacomo and Öcal, Kaan and Nonnenmacher, Marcel and Macke, Jakob H},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

%% ============================================================================
%% MARKOV CHAIN MONTE CARLO & BAYESIAN METHODS
%% ============================================================================

@book{brooks2011,
  title={Handbook of {M}arkov {C}hain {M}onte {C}arlo},
  author={Brooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li},
  year={2011},
  publisher={CRC Press}
}

@article{foreman-mackey2013,
  title={emcee: the {MCMC} hammer},
  author={Foreman-Mackey, Daniel and Hogg, David W and Lang, Dustin and Goodman, Jonathan},
  journal={Publications of the Astronomical Society of the Pacific},
  volume={125},
  number={925},
  pages={306},
  year={2013},
  publisher={IOP Publishing}
}

@article{gelman1992,
  title={Inference from iterative simulation using multiple sequences},
  author={Gelman, Andrew and Rubin, Donald B},
  journal={Statistical Science},
  volume={7},
  number={4},
  pages={457--472},
  year={1992},
  publisher={Institute of Mathematical Statistics}
}

%% ============================================================================
%% COSMOLOGY & ASTROPHYSICS
%% ============================================================================

@article{planck2020,
  title={Planck 2018 results. VI. Cosmological parameters},
  author={{Planck Collaboration} and Aghanim, N and Akrami, Y and others},
  journal={Astronomy \& Astrophysics},
  volume={641},
  pages={A6},
  year={2020},
  publisher={EDP Sciences},
  note={arXiv:1807.06209}
}

@article{sui2024,
  title={Syren-new: Precise formulae for the linear and nonlinear matter power spectra with massive neutrinos and dynamical dark energy},
  author={Sui, Ce and Bartlett, Deaglan J and Pandey, Shivam and Desmond, Harry and Ferreira, Pedro G and Wandelt, Benjamin D},
  journal={arXiv preprint arXiv:2410.14623},
  year={2024}
}

@book{dodelson2020,
  title={Modern Cosmology},
  author={Dodelson, Scott and Schmidt, Fabian},
  year={2020},
  edition={2nd},
  publisher={Academic Press}
}

@article{feigelson2012,
  title={Modern statistical methods for astronomy: with {R} applications},
  author={Feigelson, Eric D and Babu, Jogesh G},
  journal={Cambridge University Press},
  year={2012}
}

@article{peacock1992,
  title={Non-linear evolution of cosmological power spectra},
  author={Peacock, J. A. and Dodds, S. J.},
  journal={Monthly Notices of the Royal Astronomical Society},
  volume={258},
  number={1},
  pages={1P--11P},
  year={1992},
  month={sep},
  doi={10.1093/mnras/258.1.1P}
}

@book{baumann2022,
  title={Cosmology},
  author={Baumann, Daniel},
  year={2022},
  publisher={Cambridge University Press},
  address={Cambridge},
  isbn={978-1108838078}
}

%% ============================================================================
%% MACHINE LEARNING & NEURAL NETWORKS
%% ============================================================================

@article{hornik1989,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
  publisher={Elsevier}
}

@inproceedings{akiba2019,
  title={Optuna: A next-generation hyperparameter optimization framework},
  author={Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2623--2631},
  year={2019}
}

@book{cover2006,
  title={Elements of information theory},
  author={Cover, Thomas M and Thomas, Joy A},
  year={2006},
  edition={2nd},
  publisher={John Wiley \& Sons}
}

@book{gelman2013,
  title={Bayesian data analysis},
  author={Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  year={2013},
  edition={3rd},
  publisher={CRC Press}
}

@article{bellman1961,
  title={Adaptive control processes},
  author={Bellman, Richard},
  journal={Princeton University Press},
  year={1961}
}

%% ============================================================================
%% SAMPLING & EXPERIMENTAL DESIGN
%% ============================================================================

@article{mckay1979,
  title={A comparison of three methods for selecting values of input variables in the analysis of output from a computer code},
  author={McKay, M D and Beckman, R J and Conover, W J},
  journal={Technometrics},
  volume={21},
  number={2},
  pages={239--245},
  year={1979},
  publisher={Taylor \& Francis}
}

%% ============================================================================
%% END OF BIBLIOGRAPHY
%% ============================================================================
